[
["exploratory-data-analysis.html", "7 Exploratory Data Analysis 7.1 Introduction 7.2 Questions 7.3 Variation 7.4 Missing Values 7.5 Covariation 7.6 Patterns and models 7.7 ggplot2 calls 7.8 Learning more", " 7 Exploratory Data Analysis 7.1 Introduction library(&quot;tidyverse&quot;) library(&quot;viridis&quot;) library(&quot;forcats&quot;) This will also use data from nycflights13, library(&quot;nycflights13&quot;) 7.2 Questions 7.3 Variation 7.3.1 Exercise 1 Explore the distribution of each of the x, y, and z variables in diamonds. What do you learn? Think about a diamond and how you might decide which dimension is the length, width, and depth. In order to make it easier to plot them, I’ll reshape the dataset so that I can use the variables as facets. diamonds %&gt;% mutate(id = row_number()) %&gt;% select(x, y, z, id) %&gt;% gather(variable, value, -id) %&gt;% ggplot(aes(x = value)) + geom_density() + geom_rug() + facet_grid(variable ~ .) There several noticeable features of the distributions They are right skewed, with most diamonds small, but a few very large ones. There is an outlier in y, and z (see the rug) All three distributions have a bimodality (perhaps due to some sort of threshold) According to the documentation for diamonds: x is length, y is width, and z is depth. I don’t know if I would have figured that out before; maybe if there was data on the type of cuts. 7.3.2 Exercise 2 Explore the distribution of price. Do you discover anything unusual or surprising? (Hint: Carefully think about the binwidth and make sure you try a wide range of values.) The price data has many spikes, but I can’t tell what each spike corresponds to. The following plots don’t show much difference in the distributions in the last one or two digits. There are no diamonds with a price of $1,500 There’s a bulge in the distribution around $7,500. ggplot(filter(diamonds, price &lt; 2500), aes(x = price)) + geom_histogram(binwidth = 10, center = 0) ggplot(filter(diamonds), aes(x = price)) + geom_histogram(binwidth = 100, center = 0) Distribution of last digit diamonds %&gt;% mutate(ending = price %% 10) %&gt;% ggplot(aes(x = ending)) + geom_histogram(binwidth = 1, center = 0) + geom_bar() diamonds %&gt;% mutate(ending = price %% 100) %&gt;% ggplot(aes(x = ending)) + geom_histogram(binwidth = 1) + geom_bar() diamonds %&gt;% mutate(ending = price %% 1000) %&gt;% filter(ending &gt;= 500, ending &lt;= 800) %&gt;% ggplot(aes(x = ending)) + geom_histogram(binwidth = 1) + geom_bar() 7.3.3 Exercise 3 How many diamonds are 0.99 carat? How many are 1 carat? What do you think is the cause of the difference? There are more than 70 times as many 1 carat diamonds as 0.99 carat diamond. diamonds %&gt;% filter(carat &gt;= 0.99, carat &lt;= 1) %&gt;% count(carat) #&gt; # A tibble: 2 x 2 #&gt; carat n #&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 0.990 23 #&gt; 2 1.00 1558 I don’t know exactly the process behind how carats are measured, but some way or another some diamonds carat values are being “rounded up”, because presumably there is a premium for a 1 carat diamond vs. a 0.99 carat diamond beyond the expected increase in price due to a 0.01 carat increase. To check this intuition, we’d want to look at the number of diamonds in each carat range to seem if there is an abnormally low number at 0.99 carats, and an abnormally high number at 1 carat. diamonds %&gt;% filter(carat &gt;= 0.9, carat &lt;= 1.1) %&gt;% count(carat) %&gt;% print(n = 30) #&gt; # A tibble: 21 x 2 #&gt; carat n #&gt; &lt;dbl&gt; &lt;int&gt; #&gt; 1 0.900 1485 #&gt; 2 0.910 570 #&gt; 3 0.920 226 #&gt; 4 0.930 142 #&gt; 5 0.940 59 #&gt; 6 0.950 65 #&gt; 7 0.960 103 #&gt; 8 0.970 59 #&gt; 9 0.980 31 #&gt; 10 0.990 23 #&gt; 11 1.00 1558 #&gt; 12 1.01 2242 #&gt; 13 1.02 883 #&gt; 14 1.03 523 #&gt; 15 1.04 475 #&gt; 16 1.05 361 #&gt; 17 1.06 373 #&gt; 18 1.07 342 #&gt; 19 1.08 246 #&gt; 20 1.09 287 #&gt; 21 1.10 278 7.3.4 Exercise 4 Compare and contrast coord_cartesian() vs xlim() or ylim() when zooming in on a histogram. What happens if you leave binwidth unset? What happens if you try and zoom so only half a bar shows? coord_cartesian simply zooms in on the area specified by the limits. The calculation of the histogram is unaffected. ggplot(diamonds) + geom_histogram(mapping = aes(x = price)) + coord_cartesian(xlim = c(100, 5000), ylim = c(0, 3000)) #&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. However, the xlim and ylim functions first drop any values outside the limits (the ylim doesn’t matter in this case), then calculates the histogram, and draws the graph with the given limits. ggplot(diamonds) + geom_histogram(mapping = aes(x = price)) + xlim(100, 5000) + ylim(0, 3000) #&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. #&gt; Warning: Removed 14714 rows containing non-finite values (stat_bin). #&gt; Warning: Removed 5 rows containing missing values (geom_bar). 7.4 Missing Values 7.4.1 Exercise 1 What happens to missing values in a histogram? What happens to missing values in a bar chart? &gt; Why is there a difference? Missing values are removed when the number of observations in each bin are calculated. See the warning message: Removed 9 rows containing non-finite values (stat_bin) diamonds2 &lt;- diamonds %&gt;% mutate(y = ifelse(y &lt; 3 | y &gt; 20, NA, y)) ggplot(diamonds2, aes(x = y)) + geom_histogram() #&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. #&gt; Warning: Removed 9 rows containing non-finite values (stat_bin). In geom_bar, NA is treated as another category. The x aesthetic in geom_bar requires a discrete (categorical) variable, and missing values act like another category. diamonds %&gt;% mutate(cut = if_else(runif(n()) &lt; 0.1, NA_character_, as.character(cut))) %&gt;% ggplot() + geom_bar(mapping = aes(x = cut)) In a histogram, the x aesthetic variable needs to be numeric, and stat_bin groups the observations by ranges into bins. Since the numeric value of the NA observations is unknown, they cannot be placed in a particular bin, and are dropped. 7.4.2 Exercise 2 What does na.rm = TRUE do in mean() and sum()? This option removes NA values from the vector prior to calculating the mean and sum. mean(c(0, 1, 2, NA), na.rm = TRUE) #&gt; [1] 1 sum(c(0, 1, 2, NA), na.rm = TRUE) #&gt; [1] 3 7.5 Covariation 7.5.1 A categorical and continuous variable 7.5.1.1 Exercise 1 Use what you’ve learned to improve the visualization of the departure times of canceled vs. non-canceled flights. Instead of a freqplot use a box-plot nycflights13::flights %&gt;% mutate( canceled = is.na(dep_time), sched_hour = sched_dep_time %/% 100, sched_min = sched_dep_time %% 100, sched_dep_time = sched_hour + sched_min / 60 ) %&gt;% ggplot() + geom_boxplot(mapping = aes(y = sched_dep_time, x = canceled)) 7.5.1.2 Exercise 2 What variable in the diamonds dataset is most important for predicting the price of a diamond? How is that variable correlated with cut? Why does the combination of those two relationships lead to lower quality diamonds being more expensive? When looking at the effects of multiple variables on an outcome variable (here the price of a diamond), a common method is to use regression models. Regression has not been explicitly covered up to this point in the book, however, it is what is going on behind the scenes when using functions like geom_line() and geom_smooth(). These functions will compute regression models for the given data and variables, then these models are used to compute predicted values, which are plotted as a continuous line. Multiple regression is particularly powerful because it can show us which variables explain more of the data than others. However, staying true to the tutorial nature of the book, we can still explore the data without the use of regression analyses, it will just take a little bit more time. First, what are the general relationships of each variable with the price of the diamonds? ggplot(data = diamonds) + geom_boxplot(mapping = aes(x = color, y = price)) There appears to be a weak postive correlation with color. ggplot(data = diamonds) + geom_boxplot(mapping = aes(x = clarity, y = price)) There is a negative correlation with clarity, strangely, though it is also fairly weak. ggplot(data = diamonds) + geom_smooth(mapping = aes(x = depth, y = price)) #&gt; `geom_smooth()` using method = &#39;gam&#39; The relationship between depth and price is strange, but there appears to be no large systematic trend. ggplot(data = diamonds) + geom_smooth(mapping = aes(x = table, y = price)) #&gt; `geom_smooth()` using method = &#39;gam&#39; Looking at table, there is a strong upward trend after about 70 on the table variable. However, the error around this trend (shaded area) suggests that it is not a very reliable slope. The true slope could be anywhere in the shaded areas. ggplot(data = diamonds) + geom_smooth(mapping = aes(x = carat, y = price)) #&gt; `geom_smooth()` using method = &#39;gam&#39; Finally, there is a strong positive correlation with carat, and the standard error is acceptably low. We can be reasonably sure that when carat increases, the price will also increase, and it appears to do so in a much more reliable fashion than the other variables. Now that we can be reasonably sure that carat is “most important for predicting the price of a diamond,” we look at how it is correlated with cut: ggplot(data = diamonds) + geom_density(mapping = aes(x = carat, color = cut)) The “Fair” cuts seem to have a higher average carat count, though it is somewhat difficult to see on the density plot. A simple table can sometimes be easier to explore: diamonds %&gt;% group_by(cut) %&gt;% summarise(avg_carat = mean(carat, na.rm = TRUE)) #&gt; # A tibble: 5 x 2 #&gt; cut avg_carat #&gt; &lt;ord&gt; &lt;dbl&gt; #&gt; 1 Fair 1.05 #&gt; 2 Good 0.849 #&gt; 3 Very Good 0.806 #&gt; 4 Premium 0.892 #&gt; 5 Ideal 0.703 7.5.1.3 Exercise 3 Install the ggstance package, and create a horizontal box plot. How does this compare to using coord_flip()? Earlier we created a horizontal box plot of the distribution hwy by class, using geom_boxplot and coord_flip: ggplot(data = mpg) + geom_boxplot(mapping = aes(x = reorder(class, hwy, FUN = median), y = hwy)) + coord_flip() In this case the output looks the same, but in the aesthetics the x and y are flipped from the previous case. library(&quot;ggstance&quot;) ggplot(data = mpg) + geom_boxploth(mapping = aes(y = reorder(class, hwy, FUN = median), x = hwy)) 7.5.1.4 Exercise 4 One problem with box plots is that they were developed in an era of much smaller datasets and tend to display a prohibitively large number of `outlying values''. One approach to remedy this problem is the letter value plot. Install the **lvplot** package, and try usinggeom_lv()` to display the distribution of price vs cut. What do you learn? How do you interpret the plots? The boxes of the letter-value plot correspond to many more quantiles. They are useful for larger datasets because larger datasets can give precise estimates of quantiles beyond the quartiles, and in expectation, larger datasets should have more outliers (in absolute numbers). The letter-value plot is described in: Heike Hofmann, Karen Kafadar, and Hadley Wickham. 2011. “Letter-value plots: Boxplots for large data” http://vita.had.co.nz/papers/letter-value-plot.pdf library(&quot;lvplot&quot;) ggplot(diamonds, aes(x = cut, y = price)) + geom_lv() 7.5.1.5 Exercise 5 Compare and contrast geom_violin() with a faceted geom_histogram(), or a colored geom_freqpoly(). What are the pros and cons of each method? I produce plots for these three methods below. The geom_freqpoly is better for look-up: meaning that given a price, it is easy to tell which cut has the highest density. However, the overlapping lines makes it difficult to distinguish how the overall distributions relate to each other. The geom_violin and faceted geom_histogram have similar strengths and weaknesses. It is easy to visually distinguish differences in the overall shape of the distributions (skewness, central values, variance, etc). However, since we can’t easily compare the vertical values of the distribution, its difficult to look up which category has the highest density for a given price. All of these methods depend on tuning parameters to determine the level of smoothness of the distribution. ggplot(data = diamonds, mapping = aes(x = price, y = ..density..)) + geom_freqpoly(mapping = aes(colour = cut), binwidth = 500) ggplot(data = diamonds, mapping = aes(x = price)) + geom_histogram() + facet_wrap(~ cut, ncol = 1, scales = &quot;free_y&quot;) #&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ggplot(data = diamonds, mapping = aes(x = cut, y = price)) + geom_violin() + coord_flip() The violin plot was first described in Hintze JL, Nelson RD (1998). “Violin Plots: A Box Plot-Density Trace Synergism.” The American Statistician, 52(2), 181–184 7.5.1.6 Exercise 6 If you have a small dataset, it’s sometimes useful to use geom_jitter() to see the relationship between a continuous and categorical variable. The ggbeeswarm package provides a number of methods similar to geom_jitter(). List them and briefly describe what each one does. There are two methods: geom_quasirandom that produces plots that resemble something between jitter and violin. There are several different methods that determine exactly how the random location of the points is generated. geom_beeswarm creates a shape similar to a violin plot, but by offsetting the points. I’ll use the mpg box plot example since these methods display individual points, they are better suited for smaller datasets. library(&quot;ggbeeswarm&quot;) ggplot(data = mpg) + geom_quasirandom(mapping = aes(x = reorder(class, hwy, FUN = median), y = hwy)) ggplot(data = mpg) + geom_quasirandom(mapping = aes(x = reorder(class, hwy, FUN = median), y = hwy), method = &quot;tukey&quot;) ggplot(data = mpg) + geom_quasirandom(mapping = aes(x = reorder(class, hwy, FUN = median), y = hwy), method = &quot;tukeyDense&quot;) ggplot(data = mpg) + geom_quasirandom(mapping = aes(x = reorder(class, hwy, FUN = median), y = hwy), method = &quot;frowney&quot;) ggplot(data = mpg) + geom_quasirandom(mapping = aes(x = reorder(class, hwy, FUN = median), y = hwy), method = &quot;smiley&quot;) ggplot(data = mpg) + geom_beeswarm(mapping = aes(x = reorder(class, hwy, FUN = median), y = hwy)) 7.5.2 Two categorical variables 7.5.2.1 Exercise 1 How could you rescale the count dataset above to more clearly show the distribution of cut within color, or color within cut? To clearly show the distribution of cut within color, calculate a new variable prop which is the proportion of each cut within a color. This is done using a grouped mutate. diamonds %&gt;% count(color, cut) %&gt;% group_by(color) %&gt;% mutate(prop = n / sum(n)) %&gt;% ggplot(mapping = aes(x = color, y = cut)) + geom_tile(mapping = aes(fill = prop)) + scale_fill_viridis(limits = c(0, 1)) Similarly, to scale by the distribution of color within cut, diamonds %&gt;% count(color, cut) %&gt;% group_by(cut) %&gt;% mutate(prop = n / sum(n)) %&gt;% ggplot(mapping = aes(x = color, y = cut)) + geom_tile(mapping = aes(fill = prop)) + scale_fill_viridis(limits = c(0, 1)) I add limit = c(0, 1) to put the color scale between (0, 1). These are the logical boundaries of proportions. This makes it possible to compare each cell to its actual value, and would improve comparisons across multiple plots. However, it ends up limiting the colors and makes it harder to compare within the dataset. However, using the default limits of the minimum and maximum values makes it easier to compare within the dataset the emphasizing relative differences, but harder to compare across datasets. 7.5.2.2 Exercise 2 Use geom_tile() together with dplyr to explore how average flight delays vary by destination and month of year. What makes the plot difficult to read? How could you improve it? flights %&gt;% group_by(month, dest) %&gt;% summarise(dep_delay = mean(dep_delay, na.rm = TRUE)) %&gt;% ggplot(aes(x = factor(month), y = dest, fill = dep_delay)) + geom_tile() + labs(x = &quot;Month&quot;, y = &quot;Destination&quot;, fill = &quot;Departure Delay&quot;) There are several things that could be done to improve it, sort destinations by a meaningful quantity (distance, number of flights, average delay) remove missing values better color scheme (viridis) How to treat missing values is difficult. In this case, missing values correspond to airports which don’t have regular flights (at least one flight each month) from NYC. These are likely smaller airports (with higher variance in their average due to fewer observations). library(&quot;viridis&quot;) flights %&gt;% group_by(month, dest) %&gt;% summarise(dep_delay = mean(dep_delay, na.rm = TRUE)) %&gt;% group_by(dest) %&gt;% filter(n() == 12) %&gt;% ungroup() %&gt;% mutate(dest = fct_reorder(dest, dep_delay)) %&gt;% ggplot(aes(x = factor(month), y = dest, fill = dep_delay)) + geom_tile() + scale_fill_viridis() + labs(x = &quot;Month&quot;, y = &quot;Destination&quot;, fill = &quot;Departure Delay&quot;) 7.5.2.3 Exercise 3 Why is it slightly better to use aes(x = color, y = cut) rather than aes(x = cut, y = color) in the example above? It’s usually better to use the categorical variable with a larger number of categories or the longer labels on the y axis. If at all possible, labels should be horizontal because that is easier to read. However, switching the order doesn’t result in overlapping labels. diamonds %&gt;% count(color, cut) %&gt;% ggplot(mapping = aes(y = color, x = cut)) + geom_tile(mapping = aes(fill = n)) Another justification, for switching the order is that the larger numbers are at the top when x = color and y = cut, and that lowers the cognitive burden of interpreting the plot. 7.5.3 Two continuous variables 7.5.3.1 Exercise 1 Instead of summarizing the conditional distribution with a box plot, you could use a frequency polygon. What do you need to consider when using cut_width() vs cut_number()? How does that impact a visualization of the 2d distribution of carat and price? When using cut_width the number in each bin may be unequal. The distribution of carat is right skewed so there are few diamonds in those bins. ggplot(data = diamonds, mapping = aes(x = price, colour = cut_width(carat, 0.3))) + geom_freqpoly() #&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Plotting the density instead of counts will make the distributions comparable, although the bins with few observations will still be hard to interpret. ggplot(data = diamonds, mapping = aes(x = price, y = ..density.., colour = cut_width(carat, 0.3))) + geom_freqpoly() #&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Plotting the density instead of counts will make the distributions comparable, although the bins with few observations will still be hard to interpret. ggplot(data = diamonds, mapping = aes(x = price, colour = cut_number(carat, 10))) + geom_freqpoly() #&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. Since there are equal numbers in each bin, the plot looks the same if density is used for the y aesthetic (although the values are on a different scale). ggplot(data = diamonds, mapping = aes(x = price, y = ..density.., colour = cut_number(carat, 10))) + geom_freqpoly() #&gt; `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. 7.5.3.2 Exercise 2 Visualize the distribution of carat, partitioned by price. With a box plot, partitioning into an 10 bins with the same number of observations: ggplot(diamonds, aes(x = cut_number(price, 10), y = carat)) + geom_boxplot() + coord_flip() + xlab(&quot;Price&quot;) With a box plot, partitioning into an bins of $2,000 with the width of the box determined by the number of observations. I use boundary = 0 to ensure the first bin goes from $0–$2,000. ggplot(diamonds, aes(x = cut_width(price, 2000, boundary = 0), y = carat)) + geom_boxplot(varwidth = TRUE) + coord_flip() + xlab(&quot;Price&quot;) 7.5.3.3 Exercise 3 How does the price distribution of very large diamonds compare to small diamonds. Is it as you expect, or does it surprise you? The distribution of very large diamonds is more variable. I am not surprised, since I knew little about diamond prices. After the fact, it does not seem surprising (as many thing do). I would guess that this is due to the way in which diamonds are selected for retail sales. Suppose that someone selling a diamond only finds it profitable to sell it if some combination size, cut, clarity, and color are above a certain threshhold. The smallest diamonds are only profitable to sell if they are exceptional in all the other factors (cut, clarity, and color), so the small diamonds sold have similar characteristics. However, larger diamonds may be profitable regardless of the values of the other factors. Thus we will observe large diamonds with a wider variety of cut, clarity, and color and thus more variability in prices. 7.5.3.4 Exercise 4 Combine two of the techniques you’ve learned to visualize the combined distribution of cut, carat, and price. There are many options to try, so your solutions may vary from mine. Here are a few options that I tried. ggplot(diamonds, aes(x = carat, y = price)) + geom_hex() + facet_wrap(~ cut, ncol = 1) + scale_fill_viridis() ggplot(diamonds, aes(x = cut_number(carat, 5), y = price, colour = cut)) + geom_boxplot() ggplot(diamonds, aes(colour = cut_number(carat, 5), y = price, x = cut)) + geom_boxplot() 7.5.3.5 Exercise 5 Two dimensional plots reveal outliers that are not visible in one dimensional plots. For example, some points in the plot below have an unusual combination of x and y values, which makes the points outliers even though their x and y values appear normal when examined separately. ggplot(data = diamonds) + geom_point(mapping = aes(x = x, y = y)) + coord_cartesian(xlim = c(4, 11), ylim = c(4, 11)) Why is a scatterplot a better display than a binned plot for this case? In this case, there is a strong relationship between \\(x\\) and \\(y\\). The outliers in this case are not extreme in either \\(x\\) or \\(y\\). A binned plot would not reveal these outliers, and may lead us to conclude that the largest value of \\(x\\) was an outlier even though it appears to fit the bivariate pattern well. The later chapter Model Basics discusses fitting models to bivariate data and plotting residuals, which would reveal this outliers. 7.6 Patterns and models No exercises 7.7 ggplot2 calls No exercises 7.8 Learning more No exercises. "]
]
